# redis都支持哪些数据类型？应用场景有哪些

redis的key都是字符串类型的，而Value支持五种数据类型。

1. string: redis 中字符串 value 最大可为512M。可以用来做一些计数功能的缓存（也是实际工作中最常见的）。
2. list: 简单的字符串列表，按照插入顺序排序，可以添加一个元素到列表的头部（左边）或者尾部（右边），其底层实现是一个链表。可以实现一个简单消息队列功能，做基于redis的分页功能等。
3. set: 是一个字符串类型的无序集合。可以用来进行全局去重等。
4. sorted set: 是一个字符串类型的有序集合，给每一个元素一个固定的**分数score**来保持顺序。可以用来做排行榜应用或者进行范围查找等。
5. hash: 键值对集合，是一个字符串类型的 Key和 Value 的映射表，也就是说其存储的Value是一个键值对（Key- Value）。可以用来存放一些具有特定结构的信息。

# Redis有哪些数据结构 

## 字符串(SDS)

Redis只会使用c语言字符串作为字面量，大多数情况下，使用SDS(动态字符串)作为字符串表示。

### 优点

1. 常数复杂度获取字符串长度
2. 避免缓冲区溢出。
3. 减少修改字符串长度时所需要内存的重分配次数。
4. 二进制安全。
5. 兼容部分C字符串函数。

### 结构

```c
struct sdshdr{
  //记录buf数组中已使用字符的数量
  //等于SDS所保存字符串的长度
	int len;
  //记录buf数组中为使用字节的数量
  int free;
  //字符数组，用于保存字符串
  char buf[];
}
```



## 链表

是一个双端无环链表，主要用于列表键、发布和订阅、慢查询、监视器

### 结构

```c
//单个节点
typedef struct listNode{
	//前置节点
  struct listNode *prev;
  //后置节点
  struct listNode *next;
  //节点的值
  void *value;
}listNode;

//多个节点
typedef struct list{
  //表头节点
  listNode *head;
  //表尾节点
  listNode *tail;
  //链表所包含的节点数量
  unsigned long len;
  //节点值复制函数
  void *(*dup)(void *ptr);
  //节点值释放函数
  void (*free)(void *ptr);
 	///节点值对比函数
  int (*match)(void *ptr,void *key);
}list;
```



## 字典

是一个保存键值对的数据结构，主要用于数据库和哈希键。底层利用哈希表实现，每个字典有两个哈希表，一个平时使用，一个是rehash时使用。当哈希冲突的时候，使用链地址法来解决。当对哈希表进行扩展或者收缩的时候，要把现有哈希表包含的所有键值对rehash到新哈希表，而且这个过程是渐进式的。

```c
typedef struct dict {
  //类型特定函数
    dictType *type;
  //私有数据
    void *privdata;
  //哈希表
    dictht ht[2];
  //rehash索引，当rehash不在进行时，值为-1
    int trehashidx; 
} dict;
```



### 哈希表结构

```c
typedef struct dictht {
  //哈希表数组
    dictEntry **table;
  //哈希表大小
    unsigned long size;
  //哈希表大小掩码，用于计算索引值。，总是等于size-1
    unsigned long sizemask;
  //该哈希表已有节点数量
    unsigned long used;
} dictht;
```

### 哈希表节点结构

```c
typedef struct dictEntry {
  //键
    void *key;
  //值
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
  //指向下一个哈希表节点，形成链表
    struct dictEntry *next;
} dictEntry;
```

## 跳跃表

一种有序的数据结构，它通过每个节点中维持多个指向其他节点的指针，从而可以达到快速访问节点的目的。

## 集合

## 有序集合



#  String类型的底层实现 

#  Hash字典类型

#  Redis渐进式rehash 为什么

#  Redis中zset的内部实现跳跃表 为什么

#  Redis支持事务吗 

#  Redis单线程还是多线程，为什么？

Redis是单线程。

#  Redis单线程为什么还并发量那么高

#  Redis为什么快

1. 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)。
2. 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的。
3. 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。
4. 使用多路I/O复用模型。

## 什么是多路I/O复用模型

IO多路复用模型是建立在内核提供的多路分离函数select基础之上的，使用select函数可以避免同步非阻塞IO模型中轮询等待的问题。

### 执行流程

当用户线程发起请求的时候，首先会将socket(监视器)添加到select中，使用select可以让用户可以在一个线程内同时处理多个socket的I/O请求，用户可以注册多个socket，然后不断地调用select读取被激活的socket。这时阻塞等待select函数返回。当数据到达时，select被激活，select函数返回，此时用户线程才正式发起read请求，读取数据并继续执行。

#  redis内存满了怎么办 

#  Redis持久化的方法

在redis中的介绍中，我们知道了redis不光是一个基于内存的缓存，同时还支持数据的持久化。在redis的配置文件模块介绍中，我们可以设置redis的持久化方式。**redis的持久化方式有两种，即RDB和AOF的方式**。

## RDB快照方式 snapshotting）（全量持久化）

将当前内存中的数据集快照写入磁盘，实现数据的持久化，恢复时可以将快照重新载入内存。

### 触发方式

1. **自动触发：**在配置文件中，可以配置执行了多少次save就自动触发自动持久化。
2. **手动触发：**通过bgsave命令，在后台异步进行生成快照的操作，同时还可以响应客户端的请求。通过redis进程fork操作创建子进程，生成的快照由子进程负责，客户端请求只会在fork阶段被阻塞。

### 快照恢复

将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务，redis会自动加载快照文件数据到内存。但是，redis 服务器在载入 RDB 文件期间，会一直处于阻塞状态，直到载入工作完成为止。

### 优缺点

1. RDB持久化方式存在数据的丢失，因为其没有办法实现实时持久化。因为bgsave每次运行都要执行fork操作创建子进程，属于重量级操作，频繁执行成本过高，会影响系统性能。自动触发也存在丢失部分数据的情况。
2. 在恢复大数据集时候，RDB方式相对于AOF要快。

## AOF（append-only-file）（增量持久化）

在 redis配置文件的 APPEND ONLY MODE 中，可以设置AOF持久化。通过记录redis服务器所执行的写命令来记录数据库状态。恢复时可以将AOF文件载入内存，并且可以通过**redis-check-aof --fix** 进行修复AOF文件。

### AOF日志重写

1. AOF文件会随着服务器运行的时间越来越大，可以通过AOF重写来控制AOF文件的大小。
2. AOF重写会首先读取数据库中现有的键值对状态，然后根据类型使用一条命令来替代前面对键值对操作的多条命令。
3. 使用命令 bgrewriteaof 来实现AOF重写

### AOF重写缓存区

redis 是单线程工作，当AOF文件较大时重写时间会比较长，在重写 AOF 期间，redis将长时间无法处理客户端请求。为了解决这个问题，可以将 AOF 重写程序放到子进程中执行

#### AOF重写缓存区好处

1. 子进程进行 AOF 重写期间，服务器进程（父进程）可以继续处理其它客户端请求。
2. 子进程带有父进程的数据副本，使用子进程而不是线程，可以在避免使用锁的情况下，保证数据的安全性。

#### 子进程中AOF重写导致的问题

1. 子进程在进行 AOF 重写期间，服务器进程依然可以处理其它客户端请求，这就会导致数据库状态已经发生了改变，使得当前数据库数据状态和重写后的 AOF 文件中的数据不一致。
2. 也就是出现了AOF文件和数据库中数据不一致的问题。

### 数据状态不一致解决办法

1. redis 服务器设置了一个 AOF 重写缓冲区。这个缓冲区在创建子进程后开始使用，当redis服务器执行一个客户端的写请求命令，之后将这个写命令也发送到 AOF 重写缓冲区。
2. 当子进程完成 AOF 日志重写之后，给父进程发送信号，父进程接收此信号后，将 AOF 重写缓冲区的内容写到新的 AOF 文件中，保持数据的一致性。

### 优缺点

1. AOF文件可以做到秒级持久化，使用追加写的方式来写入，可读性强并且可以使用命令进行文件修复。
2. 相比于RDB文件，同样数据下AOF文件体积要大。在redis负载较高时，秒级更新AOF文件会影响性能

### 持久化策略选择

1. AOF更安全，可将数据及时同步到文件中，但需要较多的磁盘IO，AOF文件尺寸较大，文件内容恢复相对较慢也更加完整。
2. RDB持久化，安全性较差，它是正常时期数据备份及 master-slave数据同步的最佳手段，文件尺寸较小并且恢复速度较快。

#  redis主从结构 

#  redis哨兵 

#  Redis集群  

#  集群是如何判断是否有某个节点挂掉 

#  分布式锁作用 

#  一致性哈希 

# Redis可能出现的问题

## 缓存雪崩

**缓存雪崩**是缓存同一时间大面积的失效，这个时候又来的一波请求都到数据库上，导致数据库连接异常。

**解决办法：**

1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
2. 一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。
3. 给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存。

## 缓存击穿

**缓存击穿**是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。

**解决办法：**

1. 使用互斥锁，只让一个请求去load DB，成功之后重新写缓存，其余请求没有获取到互斥锁，可以尝试重新获取缓存中的数据。
2. 设置热点数据永远不过期。

## 缓存穿透

**缓存穿透**是故意的去请求缓存中不存在的数据，导致请求都打到了数据库上，导致数据库异常。

**解决办法**：

1. 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；
2. 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击
3. 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力

## 缓存预热

**缓存预热**就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户直接查询事先被预热的缓存数据。

**解决方案**

1. 直接写个缓存刷新页面，上线时手工操作一下；
2. 数据量不大，可以在项目启动的时候自动进行加载；
3. 定时刷新缓存；

### 缓存降级

当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。

**缓存降级**的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。

在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：

1. 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；
2. 警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；
3. 错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；
4. 严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。

### 数据库和缓存的双写一致性问题

**举例：**在高并发请求下很容易导致数据不一致的问题。

如果你的业务需要保证数据的强一致性，那么建议不要使用缓存。在数据库中和缓存数据的删除或者写入过程中，如果有失败的情况，会导致数据的不一致。

**解决办法：**

- **双删延时的解决办法。**可以先删除缓存数据，然后再更新数据库数据，最后再隔固定的时间再次删除缓存。
- **更新数据库产生的binlog订阅（使用canal）**。将有变化的key记录下来，并且尝试去不断的去删除缓存（如果上次删除缓存失败）